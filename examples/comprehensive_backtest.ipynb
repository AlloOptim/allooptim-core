{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5edd2329",
   "metadata": {},
   "source": [
    "# Comprehensive Portfolio Optimization Backtest\n",
    "\n",
    "This notebook demonstrates a comprehensive backtest of multiple portfolio optimization algorithms available in the AlloOptim library.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This backtest compares the performance of:\n",
    "- **13 individual optimizers** from the AlloOptim library\n",
    "- **Ensemble methods** (average of all optimizer weights)\n",
    "- **S&P 500 benchmark** for comparison\n",
    "\n",
    "### Backtest Configuration\n",
    "- **Period**: 2014-12-31 to 2024-12-31 (10 years)\n",
    "- **Rebalancing**: Every 5 trading days\n",
    "- **Lookback**: 90 days for optimizer estimation\n",
    "- **Universe**: ~400 assets from Alpaca universe\n",
    "- **Execution**: Perfect execution (target = actual weights)\n",
    "\n",
    "### Performance Metrics\n",
    "- Sharpe ratio, maximum drawdown, time underwater\n",
    "- Risk-adjusted returns, portfolio turnover\n",
    "- Daily return statistics, computation time\n",
    "- Optimizer clustering analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7852f214",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import the necessary libraries for backtesting, data analysis, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379c0f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# AlloOptim imports\n",
    "from allo_optim.backtest.backtest_config import BacktestConfig, config\n",
    "from allo_optim.backtest.backtest_engine import BacktestEngine\n",
    "from allo_optim.backtest.backtest_report import generate_report\n",
    "from allo_optim.backtest.backtest_visualizer import create_visualizations\n",
    "from allo_optim.backtest.cluster_analyzer import ClusterAnalyzer\n",
    "\n",
    "# Notebook utilities\n",
    "from notebook_utils import (\n",
    "    display_optimizer_comparison,\n",
    "    plot_returns_distribution,\n",
    "    create_performance_summary,\n",
    "    plot_cumulative_returns,\n",
    "    save_notebook_results,\n",
    "    print_backtest_summary\n",
    ")\n",
    "\n",
    "# Configure plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configure logging to show in notebook\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70127b7",
   "metadata": {},
   "source": [
    "## 2. Backtest Configuration\n",
    "\n",
    "Let's examine and display the backtest configuration parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0328a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display backtest configuration\n",
    "print(\"Backtest Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Start Date: {config.start_date}\")\n",
    "print(f\"End Date: {config.end_date}\")\n",
    "print(f\"Rebalancing Frequency: Every {config.rebalance_frequency} trading days\")\n",
    "print(f\"Lookback Window: {config.lookback_days} days\")\n",
    "print(f\"Results Directory: {config.results_dir}\")\n",
    "print(f\"Random Seed: Not used in current implementation\")\n",
    "\n",
    "# Show date range for the report\n",
    "start_date, end_date = config.get_report_date_range()\n",
    "print(f\"Report Date Range: {start_date} to {end_date}\")\n",
    "\n",
    "print(\"\\nBacktest configuration loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f62ac36",
   "metadata": {},
   "source": [
    "## 3. Run the Backtest\n",
    "\n",
    "Now we'll execute the comprehensive backtest. This will test all available optimizers and may take several minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a91035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Initialize and run the backtest\n",
    "print(\"Initializing backtest engine...\")\n",
    "backtest_engine = BacktestEngine(config)\n",
    "\n",
    "print(\"Running comprehensive backtest...\")\n",
    "print(\"This may take several minutes depending on your hardware...\")\n",
    "\n",
    "# Run the backtest\n",
    "results = backtest_engine.run_backtest()\n",
    "\n",
    "if results:\n",
    "    print(f\"\\n‚úÖ Backtest completed successfully!\")\n",
    "    print(f\"   Tested {len(results)} optimizers\")\n",
    "    print(f\"   Results available for analysis\")\n",
    "else:\n",
    "    print(\"‚ùå Backtest failed - no results generated\")\n",
    "    raise RuntimeError(\"Backtest execution failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33818b0a",
   "metadata": {},
   "source": [
    "## 4. Analyze Results\n",
    "\n",
    "Let's examine the backtest results and performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d457d4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract performance data for analysis\n",
    "performance_data = []\n",
    "optimizer_names = []\n",
    "\n",
    "for name, data in results.items():\n",
    "    if 'metrics' in data:\n",
    "        row = {'optimizer': name}\n",
    "        row.update(data['metrics'])\n",
    "        performance_data.append(row)\n",
    "        optimizer_names.append(name)\n",
    "\n",
    "# Create DataFrame for analysis\n",
    "df_results = pd.DataFrame(performance_data)\n",
    "df_results = df_results.sort_values('sharpe_ratio', ascending=False)\n",
    "\n",
    "print(\"Backtest Results Summary:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total optimizers tested: {len(df_results)}\")\n",
    "print(f\"Best Sharpe ratio: {df_results.iloc[0]['sharpe_ratio']:.3f} ({df_results.iloc[0]['optimizer']})\")\n",
    "print(f\"Worst Sharpe ratio: {df_results.iloc[-1]['sharpe_ratio']:.3f} ({df_results.iloc[-1]['optimizer']})\")\n",
    "print(\".3f\")\n",
    "print(\".3f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e4d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 10 performers using utility function\n",
    "print(\"\\nTop 10 Optimizers by Sharpe Ratio:\")\n",
    "print(\"-\" * 80)\n",
    "top_10_df = display_optimizer_comparison(results, top_n=10)\n",
    "print(top_10_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9239025",
   "metadata": {},
   "source": [
    "## 5. Clustering Analysis\n",
    "\n",
    "Let's analyze how the optimizers cluster based on their performance and portfolio similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fd1cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering analysis\n",
    "print(\"Performing optimizer clustering analysis...\")\n",
    "cluster_analyzer = ClusterAnalyzer(results)\n",
    "clustering_results = cluster_analyzer.analyze_clusters()\n",
    "\n",
    "print(\"‚úÖ Clustering analysis completed!\")\n",
    "\n",
    "# Display clustering summary\n",
    "if clustering_results and 'summary' in clustering_results:\n",
    "    print(\"\\nClustering Analysis Summary:\")\n",
    "    print(\"-\" * 40)\n",
    "    summary = clustering_results['summary']\n",
    "    print(f\"Number of clusters: {summary.get('n_clusters', 'N/A')}\")\n",
    "    print(f\"Silhouette score: {summary.get('silhouette_score', 'N/A'):.3f}\")\n",
    "    print(f\"Calinski-Harabasz score: {summary.get('calinski_harabasz_score', 'N/A'):.1f}\")\n",
    "\n",
    "    # Show cluster sizes\n",
    "    if 'cluster_sizes' in summary:\n",
    "        print(f\"\\nCluster sizes: {summary['cluster_sizes']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f5c162",
   "metadata": {},
   "source": [
    "## 7. Visualizations\n",
    "\n",
    "Let's create visualizations to better understand the backtest results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2cf784",
   "metadata": {},
   "source": [
    "## 6. Returns Distribution Analysis\n",
    "\n",
    "Let's examine the distribution of daily returns for the top performing optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6eeb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot returns distribution for top 5 optimizers\n",
    "print(\"Creating returns distribution plots...\")\n",
    "fig = plot_returns_distribution(results, top_n=5)\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Returns distribution analysis completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2e2d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "print(\"Creating visualizations...\")\n",
    "create_visualizations(results, clustering_results, config.results_dir)\n",
    "print(\"‚úÖ Visualizations created and saved to results directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f3a0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative returns for top optimizers\n",
    "print(\"Creating cumulative returns comparison...\")\n",
    "fig = plot_cumulative_returns(results, top_n=5)\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Cumulative returns plot created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf4ec81",
   "metadata": {},
   "source": [
    "## 8. Generate Report\n",
    "\n",
    "Let's generate a comprehensive report of the backtest results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2df35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive report\n",
    "print(\"Generating comprehensive backtest report...\")\n",
    "report = generate_report(results, clustering_results, config)\n",
    "\n",
    "# Save report to file\n",
    "report_path = config.results_dir / \"comprehensive_backtest_report.md\"\n",
    "with open(report_path, \"w\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"‚úÖ Report saved to: {report_path}\")\n",
    "\n",
    "# Display first part of the report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REPORT PREVIEW (first 20 lines)\")\n",
    "print(\"=\"*80)\n",
    "lines = report.split('\\n')[:20]\n",
    "for line in lines:\n",
    "    print(line)\n",
    "print(\"...\")\n",
    "print(f\"\\nüìÑ Full report available at: {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305af3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save notebook results to CSV files\n",
    "print(\"Saving notebook results to CSV files...\")\n",
    "results_dir = save_notebook_results(results, clustering_results, \"notebook_results\")\n",
    "print(f\"‚úÖ Results saved to: {results_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a502e3d",
   "metadata": {},
   "source": [
    "## 9. Summary and Next Steps\n",
    "\n",
    "### What We've Accomplished\n",
    "‚úÖ **Comprehensive backtest** of 13+ portfolio optimization algorithms  \n",
    "‚úÖ **Performance analysis** with key risk-adjusted metrics  \n",
    "‚úÖ **Clustering analysis** to understand optimizer relationships  \n",
    "‚úÖ **Returns distribution analysis** for top performers  \n",
    "‚úÖ **Cumulative returns comparison** over time  \n",
    "‚úÖ **Visualizations** for intuitive result exploration  \n",
    "‚úÖ **Detailed report** with all findings and insights  \n",
    "‚úÖ **CSV exports** for further analysis  \n",
    "\n",
    "### Key Findings\n",
    "- **Best performing optimizer**: {df_results.iloc[0]['optimizer']} (Sharpe: {df_results.iloc[0]['sharpe_ratio']:.3f})\n",
    "- **Total optimizers tested**: {len(df_results)}\n",
    "- **Test period**: 10 years (2014-2024)\n",
    "- **Rebalancing**: Every 5 trading days\n",
    "\n",
    "### Files Generated\n",
    "- üìä **Visualizations**: PNG plots in `{config.results_dir}/plots/`\n",
    "- üìã **Report**: Markdown report at `{report_path}`\n",
    "- üìà **Results**: CSV data at `{config.results_dir}/backtest_results.csv`\n",
    "- üíæ **Notebook Results**: CSV files in `notebook_results/`\n",
    "\n",
    "### Next Steps\n",
    "1. **Analyze specific optimizers** in more detail\n",
    "2. **Compare different rebalancing frequencies**\n",
    "3. **Test on different time periods**\n",
    "4. **Incorporate transaction costs**\n",
    "5. **Add custom optimizers** to the comparison\n",
    "\n",
    "---\n",
    "**Backtest completed successfully!** üéâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10813047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comprehensive backtest summary\n",
    "print_backtest_summary(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allo-optim-py3.12 (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
